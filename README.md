# LMR-CL : Learning Modality-Fused Representations with Contrastive Loss for Multimodal Emotion Recognition 


The "Han Hye-sung" team, composed of students from the Graduate School of Software Convergence at Kyung Hee University, won the Minister of Science and ICT Award at the **'2nd ETRI Human Understanding AI Paper Competition'** held by the Electronics and Telecommunications Research Institute (ETRI). 

(link : https://www.gttkorea.com/news/articleView.html?idxno=5685)

paper link : https://www.dbpia.co.kr/pdf/pdfView.do?nodeId=NODE11488658&googleIPSandBox=false&mark=0&ipRange=false&b2cLoginYN=false&isPDFSizeAllowed=true&accessgl=Y&language=ko_KR&hasTopBanner=true

This project implements a multimodal emotion recognition system based on the KEMDy20 dataset using text (BERT-based), audio (Wav2Vec2-based), and biosignal data. The project is organized in a modular fashion with separate components for data preprocessing, dataset creation, data loading, model definition, training, and evaluation.
